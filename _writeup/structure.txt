
Introduction:
To implement a clustered forward renderer each type of light needs a corresponding test function that checks whether it is inside a cluster. For point lights we simply precompute on the CPU the noticable range of the light and perform a simply sphere test with the clusters bounds.

The ideal size of each cluster would depend on how light sources are used in a specific game, and can be finetuned empirically. DOOM 2016 uses 16:9:24 [Cite], it's close quarters gameplay means most light sources mostly occupy larger portions of the screen.

When it comes to area lights, the using smaller clusters and a tight assignment algorithm seems to be the way to go, from a small benchmark I made in my PBR renderer, it took 50 overlapping point lights to inflict the same performance penalty that a single 4-point LTC-area light. [24feb benchmark pngs]

And in practice, I've found that the compute shaders will always have a tiny fraction of the workload that the fragment shader does, and so we should aim to make the test functions for culling lights as tight fitting as possible to minimize the fragment shader workload.
- For this reason, froxel shaped clusters may slightly reduce the fragment shader load, but the math for testing with different types of lights is less trivial to reason about than axis aligned voxel shaped clusters (AABBs - axis aligned bounding boxes).


Background:
- Area light shading
 o Older methods

o Physically-based lights are the ones that occupy area, they create more beautiful games but I mentioned above, are wildly more computationally expensive than point lights.
 Traditionally in games, the sun was modelled as a directional light, we typically reason that since the Sun is far enough away that it's rays are approximately parallel, we can simply model it as incoming light from a constant direction. But of course, we can see the our Sun has size in the sky, it has consequences like causing soft shadows, and in terms of light transport it really should be modelled as a spherical area light.
 Look at the beutiful sun in DecimaSiggraph207 slide 16/70.


Explanation that with tight cluster assignment,
as long as the scene doesn't overlap too many area lights
the number of calculations per pixel can be kept low.
E.g. the scene may have hundreds of area lights, but
most pixels only compute 3-5 area lights.


glTF: aims to be the format that your both the 3d model software uses, and the game can use,
and other things like 3d scanners.
- When it comes to rendering this means its a format that species data with a lot
of indirections which makes it hard to make a format for.



Section on developing a PBR renderer:
- E.g. stuff like the disney brdf and loading base color and emissive as sRGB and others in linear space.


